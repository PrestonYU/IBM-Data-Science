{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<h1 align = \"center\"> Time-constrained Tourists + Immigrants Problems </h1>\n<h3 align = \"center\"> Providing a City Guide for Foreigners for any purpose </h3>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Shun-Ping (Preston) Yu <br><br>\n16th July 2021"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Introduction"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "There are lots of foreign and local people in a city. Especially for foreign visiters, they come to a city for many purposes, such as business, travelling, immigration and so on. In this capstone project, we will take the Big Apple, New York City, as example to demonstrate how to solve foreign visiters' common problems.  "
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Business Problem"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Imagine your are running a tourist agency company which is in capable of not only helping immigrants find suitable residential place to settle down, but also planning tourist packages for every customers. The aim is to satisfy all your customers for any purpose. One day, you get 2 different cases from different customers. <br> \n<li> Customer A - An immigrant from Taiwan : Searching for suitable area to live in </li>\n<li> Customer B - A group of tourists : Visiting as many top attractions as possible in 3 days (because they will move on to the next city in the 4th day) </li>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Data Description"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<h4> Geolocation data for New York City </h4>\nI reused the data from the previous lab (https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork/labs/newyork_data.json) and extract the following information.<br>\n<li> Borough </li>\n<li> Neighborhood </li>\t\n<li> Latitude\t</li>\n<li> Longitude </li>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<h4> NYC Property Sales </h4>\nI used the data from kaggle (https://www.kaggle.com/new-york-city/nyc-property-sales) and extract the following information.<br>\n<li> Neighborhood </li>\t\n<li> Sale Price\t</li>\nThis dataset is a record of every building or building unit (apartment, etc.) sold in the New York City property market over a 12-month period."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<h4> Google OR-Tools Traveling Salesperson Problem (TSP) </h4>\nI used the open-source routing package from Google OR-Tools.(https://developers.google.com/optimization/routing/tsp) <br>\nTSP is used for finding the shortest route for a salesperson who needs to visit customers at different locations and return to the starting point. A TSP can be represented by a graph, in which the nodes correspond to the locations, and the edges (or arcs) denote direct travel between locations."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<h4> Foursquare API Data </h4>\nWe will need data about different venues in different neighbourhoods of that specific borough. In order to gain that information we will use \"Foursquare\" locational information. Foursquare is a location data provider with information about all manner of venues and events within an area of interest. Such information includes venue names, locations, menus and even photos. As such, the foursquare location platform will be used as the sole data source since all the stated required information can be obtained through the API.\n\nAfter finding the list of neighbourhoods, we then connect to the Foursquare API to gather information about venues inside each and every neighbourhood. The data retrieved from Foursquare contained information of venues within a specified distance of the longitude and latitude of the postcodes. The information obtained per venue as follows:<br>\n\n<li> Neighbourhood : Name of the Neighbourhood </li>\n<li> Neighbourhood Latitude : Latitude of the Neighbourhood </li>\n<li> Neighbourhood Longitude : Longitude of the Neighbourhood </li>\n<li> Venue : Name of the Venue </li>\n<li> Venue Latitude : Latitude of Venue </li>\n<li> Venue Longitude : Longitude of Venue </li>\n<li> Venue Category : Category of Venue </li>"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Methodology"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "We will be creating our model with the help of Python so we start off by importing all the required packages, so let's download all the dependencies that we will need."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import numpy as np # library to handle data in a vectorized manner\n\nimport pandas as pd # library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json # library to handle JSON files\n\n!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\nfrom sklearn.cluster import DBSCAN\n\n!pip install ortools\n!conda install -c conda-forge folium=0.5.0 --yes # uncomment this line if you haven't completed the Foursquare API lab\nimport folium # map rendering library",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Package breakdown:\n\n<li> Pandas : To collect and manipulate data when analyzing </li> \n<li> requests : Handle http requests </li> \n<li> matplotlib : Detailing the generated maps </li> \n<li> folium : Generating maps of New York City </li> \n<li> sklearn : To import Kmeans and DBSCAN which are the machine learning models that we are using </li> \n<li> ortools : OR-Tools is an open source software suite for optimization, tuned for tackling the world's toughest problems in vehicle routing, flows, integer and linear programming, and constraint programming. </li> "
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "The approach taken here is to explore the city, plot the map to show the neighbourhoods being considered and then build our model by clustering all of the similar neighbourhoods or nearby top attractions together, and finally plot the new map with the clustered results. We draw insights and then compare and discuss our findings."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "--------------------------------------------------------------------------------------------------------------------------------------------------------"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Part A.   Immigrants Problem - Searching for suitable area to live in"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "We begin to start collecting and refining the data needed for the our business solution to work."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 1) Data Collection - Download and Explore Dataset"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "In the data collection stage, we begin with collecting the required data such as postal codes, neighbourhoods and boroughs in New York City."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!wget -q -O 'newyork_data.json' https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DS0701EN-SkillsNetwork/labs/newyork_data.json\nwith open('newyork_data.json') as json_data:\n    newyork_data = json.load(json_data)\n    \nneighborhoods_data = newyork_data['features']",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "After arranging Neighborhood JSON file to DataFrame Format:"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# define the dataframe columns\ncolumn_names = ['Borough', 'Neighborhood', 'Latitude', 'Longitude'] \n\n# instantiate the dataframe\nneighborhoods = pd.DataFrame(columns=column_names)\n\n# loop through the data and fill the dataframe one row at a time.\nfor data in neighborhoods_data:\n    borough = neighborhood_name = data['properties']['borough'] \n    neighborhood_name = data['properties']['name']\n        \n    neighborhood_latlon = data['geometry']['coordinates']\n    neighborhood_lat = neighborhood_latlon[1]\n    neighborhood_lon = neighborhood_latlon[0]\n    \n    neighborhoods = neighborhoods.append({'Borough': borough,\n                                          'Neighborhood': neighborhood_name,\n                                          'Latitude': neighborhood_lat,\n                                          'Longitude': neighborhood_lon}, ignore_index=True)\n\nneighborhoods.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<img src=\"https://imgur.com/EAjAtlS.png\">"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Then, let's create a map of New York with neighborhoods superimposed on top"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# create map of New York using latitude and longitude values\nmap_newyork = folium.Map(location=[latitude, longitude], zoom_start=10)\n\n# add markers to map\nfor lat, lng, borough, neighborhood in zip(neighborhoods['Latitude'], neighborhoods['Longitude'], neighborhoods['Borough'], neighborhoods['Neighborhood']):\n    label = '{}, {}'.format(neighborhood, borough)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_newyork)  \n    \nmap_newyork",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<img src=\"https://imgur.com/eQiADyG.png\">"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 2) Data Processing - Data Cleaning and Wrangling + Exploratory Data Analysis + Feature Engineering"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "After using Foursquare API, we are able to get the venue and venue categories around each neighbourhood in New York City. This will help us get venue categories which is important for our analysis."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Getting the venues in New York City\nnyc_venues = getNearbyVenues(names=neighborhoods['Neighborhood'],\n                                   latitudes=neighborhoods['Latitude'],\n                                   longitudes=neighborhoods['Longitude']\n                                  )\n\nnyc_venues.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<img src=\"https://imgur.com/fWi1LAK.png\">"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "**2.1) Define the Nearest Neighborhood for each Venue**"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Seems like there are some venues which have been categorized to multiple neighborhoods. Let's calculate the distance (in meter) between venues and neighborhoods and determine the nearest neighborhood for each venue, so that it won't affect the analysis afterwards. "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import math\nnyc_venues['distance_to_neighborhood_meters'] = 0\nfor i in range(0,len(nyc_venues)):\n    nyc_venues['distance_to_neighborhood_meters'][i] = round(math.sqrt((nyc_venues['Venue Latitude'][i] - nyc_venues['Neighborhood Latitude'][i])**2 + (nyc_venues['Venue Longitude'][i] - nyc_venues['Neighborhood Longitude'][i])**2) * 111320,2)\n    \nnyc_venues.head()    ",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<img src=\"https://imgur.com/44gpyjJ.png\">"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Display only the nearest neighborhood for each venue and exclude all the other non-nearest ones"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "unique_venue = nyc_venues[['Venue','Venue Latitude','Venue Longitude','Venue Category']].drop_duplicates()\nunique_venue = unique_venue.reset_index(drop = True)\nmin_distance_to_neighborhood_per_venue = {}\n\nfor i in range(0,len(unique_venue)):\n    min_distance_to_neighborhood_per_venue[i] = min(nyc_venues[nyc_venues['Venue'] == unique_venue['Venue'][i]]['distance_to_neighborhood_meters'])\n    \nmin_distance_to_neighborhood_per_venue_df = pd.DataFrame.from_dict(min_distance_to_neighborhood_per_venue, orient='index') \nunique_venue2 = pd.concat([unique_venue,min_distance_to_neighborhood_per_venue_df], axis = 1)\n\nnyc_venues_neighborhood = nyc_venues[['Neighborhood','Neighborhood Latitude','Neighborhood Longitude','distance_to_neighborhood_meters','Venue']]\nnyc_venues_df = unique_venue2.merge(nyc_venues_neighborhood, left_on = [0,'Venue'], right_on = ['distance_to_neighborhood_meters','Venue'], how = 'inner')\nnyc_venues_df = nyc_venues_df.drop([0], axis = 1)\nnyc_venues_df.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<img src=\"https://imgur.com/fWrV7RS.png\">"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "**2.2) Import House Sale Price Data + Data Cleaning**"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "According to our customers' request on searching for suitable area to live in, let's add the house sale price data to help our customer choosing the ideal place based on their concerns and budgets."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\n# import data from IBM Watson\ndf_data_1 = pd.read_csv(body)\ndf_data_1.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<img src=\"https://imgur.com/kMPm2AJ.png\">"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Data Wrangling \ndf_data = df_data.reset_index(drop = True)\ndf_data = df_data[df_data['SALE PRICE'] != ' -  ']\ndf_data = df_data.reset_index(drop = True)\ndf_data['SALE PRICE'] = df_data['SALE PRICE'].astype('int64')\ndf_data = df_data[['NEIGHBORHOOD','SALE PRICE']]\ndf_data_grouped = df_data.groupby('NEIGHBORHOOD').mean().reset_index()\ndf_data_grouped.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<img src=\"https://imgur.com/D21ng2k.png\">"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now we have the average house sale price for each neighborhood in New York City!"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "**2.3) Define the Composition of Neighborhoods**"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Using one hot encoding to encode venue categories to get a better result for our upcoming clustering steps"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# one hot encoding\nnyc_onehot = pd.get_dummies(nyc_venues_df[['Venue Category']], prefix=\"\", prefix_sep=\"\")\nnyc_onehot = nyc_onehot.drop(['Neighborhood'], axis = 1)\n\n# add neighborhood column back to dataframe\nnyc_onehot['_Neighborhood'] = nyc_venues_df['Neighborhood'] \n\n# move neighborhood column to the first column\nfixed_columns = [nyc_onehot.columns[-1]] + list(nyc_onehot.columns[:-1])\nnyc_onehot = nyc_onehot[fixed_columns]\n\na = list(nyc_onehot.columns)\na[0] = 'Neighborhood'\nnyc_onehot.columns = a\n\nnyc_onehot.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Group rows by neighborhood and by taking the mean of the frequency of occurrence of each category"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "nyc_grouped = nyc_onehot.groupby('Neighborhood').mean().reset_index()\nnyc_grouped",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<img src=\"https://imgur.com/d776Ibc.png\">"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Create a new dataframe and display the top 20 venues for each neighborhood"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "num_top_venues = 20\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighborhood']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Neighborhood'] = nyc_grouped['Neighborhood']\n\nfor ind in np.arange(nyc_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(nyc_grouped.iloc[ind, :], num_top_venues)\n\nneighborhoods_venues_sorted.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<img src=\"https://imgur.com/PwEcsK4.png\">"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "By doing so, we can have a clear picture of the composition of each neighborhood."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "**2.4) Merge nyc_grouped Data with House Sale Price Data**"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Switch to Upper Case\nfor i in range(0,len(nyc_grouped)):\n    nyc_grouped['Neighborhood'][i] = nyc_grouped['Neighborhood'][i].upper() \n\n# Merge 2 datasets\nnyc_grouped_house_price = nyc_grouped.merge(df_data_grouped, left_on='Neighborhood', right_on='NEIGHBORHOOD', how='left')\nnyc_grouped_house_price.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Data Cleaning and Fill the NAs \nnyc_grouped_house_price = nyc_grouped_house_price.drop(['NEIGHBORHOOD'], axis = 1)\nnyc_grouped_house_price = nyc_grouped_house_price.fillna(0)  # Set the NA house price to 0 as a special outlier in order to prevent inaccurate clustering\nnyc_grouped_house_price.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 3) Clustering - Applying KMeans Machine Learning Algorithm"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Run kmeans to cluster the neighborhood into 5 clusters"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# set number of clusters\nkclusters = 5\n\nnyc_grouped_house_price_clustering = nyc_grouped_house_price.drop('Neighborhood', 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(nyc_grouped_house_price_clustering)\n\n# add clustering labels\nneighborhoods_venues_sorted.insert(0, 'Cluster Labels', kmeans.labels_)\n\nnyc_merged = neighborhoods\n\n# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\nnyc_merged = nyc_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n\nnyc_merged.head() # check the last columns!",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<img src=\"https://imgur.com/3VUnKTg.png\">"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Visualize the resulting clusters"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<img src=\"https://imgur.com/ZVwjKhf.png\">"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "The red dots symbolize the neighborhoods which are categorized as cluster 1, and they cover most of the area in New York City. The light green dots symbolize the neighborhood which are categorized as cluster 4, and they are mainly located in Manhattan. "
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 4) Data Visualization - Determine the differences among Clusters"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Switch to Upper Case\nfor i in range(0,len(neighborhoods_venues_sorted)):\n    neighborhoods_venues_sorted['Neighborhood'][i] = neighborhoods_venues_sorted['Neighborhood'][i].upper() \n\n# Merge 2 datasets\nneighborhoods_venues_sorted_house_price = neighborhoods_venues_sorted.merge(df_data_grouped, left_on='Neighborhood', right_on='NEIGHBORHOOD', how='left')\n\n# Data Cleaning and Fill the NAs \nneighborhoods_venues_sorted_house_price = neighborhoods_venues_sorted_house_price.drop(['NEIGHBORHOOD'], axis = 1)\nneighborhoods_venues_sorted_house_price = neighborhoods_venues_sorted_house_price.fillna(0)  # Set the NA house price to 0 as a special outlier in order to prevent inaccurate clustering\nneighborhoods_venues_sorted_house_price.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "***Cluster 1***"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "nyc_cluster_1_df = nyc_merged2[nyc_merged2['Cluster Labels'] == 0].reset_index(drop = True)\nnyc_cluster_1_df.head()",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import numpy as np\nimport matplotlib.pyplot as plt\n\nCluster1_Neighborhood = neighborhoods_venues_sorted_house_price[neighborhoods_venues_sorted_house_price['Cluster Labels'] == 0]['Neighborhood']\nCluster1_SalePrice = neighborhoods_venues_sorted_house_price[neighborhoods_venues_sorted_house_price['Cluster Labels'] == 0]['SALE PRICE']\n\nx = np.arange(len(Cluster1_Neighborhood))\nplt.bar(x, Cluster1_SalePrice, color=['blue'])\nplt.xticks(x, Cluster1_Neighborhood)\nplt.xlabel('Cluster1_Neighborhood')\nplt.ylabel('Cluster1_SalePrice')\nplt.title('Cluster1_Neighborhood House Sale Price')\nplt.show()\n\nprint(\"The average price of the house in Cluster 1 region : $\" , round(Cluster1_SalePrice.mean(),2))",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<img src=\"https://imgur.com/e1Eh8jf.png\">"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "***Cluster 2***"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<img src=\"https://imgur.com/iUFJbms.png\">"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "***Cluster 3***"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<img src=\"https://imgur.com/0LoGZ3j.png\">"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "***Cluster 4***"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<img src=\"https://imgur.com/TxA2pEn.png\">"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "***Cluster 5***"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<img src=\"https://imgur.com/pThIg3u.png\">"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 5) Results and Conclusion"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "According to the above analysis, we can conclude that Neighborhoods in Cluster 1 are probably residential areas, since the average house price is the lowest among clusters and it consists of restaurants, shops, and stores. We can highly recommend our immigrant customers to live in Cluster 1. For Cluster 2 and 3, the top 2 highest house price in New York City, where hotels and entertainment venues mostly locate, probably we can see lots of people from different states and countries in these 2 areas. Neighborhoods in Cluster 4 mostly locate in Manhattan and also consist of restaurants, shops, and stores. We could also recommend our immigrant customers to live in Cluster 4 if our customers have more budget on either renting or purchasing their house. Neighborhoods in Cluster 5 are probably the CBD (Central Business District), since the cluster consists of luxurious venues, such as jewelry stores, hotels and bars. <br><br>\n\nThe purpose of this problem is to explore a city in a glimpse, and also in a scientific way. We can even discover that the house sale price might be also related with the composition of the clusters. All in all, now it's up to how our immigrant customers choice on where to reside."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "---------------------------------------------------------------------------------------------------------------------------------------------------------------"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "## Part B. Time-constrained Tourists Problem - Visiting as many top attractions as possible in 3 days"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 1) Data Collection - Download and Explore Dataset"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Assuming the tourists live in somewhere around Lincoln Square, let's get the top 100 venues that are in Lincoln Square within a radius of 10 kilometers."
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "LIMIT = 100\nradius = 10000\n\nurl = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n    CLIENT_ID, \n    CLIENT_SECRET, \n    VERSION, \n    float(neighborhoods['Latitude'][neighborhoods['Neighborhood'] == 'Lincoln Square']), # lat of Lincoln Square\n    float(neighborhoods['Longitude'][neighborhoods['Neighborhood'] == 'Lincoln Square']), # lon of Lincoln Square\n    radius, \n    LIMIT)\n\nurl",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "venues = results['response']['groups'][0]['items']\n    \nnearby_venues = json_normalize(venues) # flatten JSON\n\n# filter columns\nfiltered_columns = ['venue.name', 'venue.categories', 'venue.location.lat', 'venue.location.lng']\nnearby_venues =nearby_venues.loc[:, filtered_columns]\n\n# filter the category for each row\nnearby_venues['venue.categories'] = nearby_venues.apply(get_category_type, axis=1)\n\n# clean columns\nnearby_venues.columns = [col.split(\".\")[-1] for col in nearby_venues.columns]\n\nnearby_venues",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<img src=\"https://imgur.com/xik7Jmw.png\">"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 2) Data Processing - Data Cleaning and Wrangling"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Since the tourists have little of time to explore the city, we will filter worthy attractions for them"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "major_sightseeing_spots = ['Opera House', 'Performing Arts Venue', 'Park','Fountain', 'Plaza', 'Theater','Garden', 'Art Museum', 'Concert Hall','Scenic Lookout', 'Waterfront', 'Church','Exhibit', 'Reservoir','Museum',  'Field', 'Art Gallery', 'Market']\n\nmajor_sightseeing_venues = nearby_venues[nearby_venues['categories'].isin(major_sightseeing_spots)]\nmajor_sightseeing_venues = major_sightseeing_venues.reset_index(drop = True)\nmajor_sightseeing_venues",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 3) Clustering - Applying DBSCAN Machine Learning Algorithm"
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Apply DBSCAN Algorithm\nX = major_sightseeing_venues[['lat','lng']]\nclustering = DBSCAN(eps=0.005,min_samples=3).fit(X)\n\n# add clustering labels\nmajor_sightseeing_venues.insert(0, 'Cluster Labels', clustering.labels_)\ncluster_num = len(major_sightseeing_venues['Cluster Labels'].unique())\n\n# create map\nmap_clusters2 = folium.Map(location=[latitude, longitude], zoom_start=12)\n\n# set color scheme for the clusters\nx = np.arange(cluster_num)\nys = [i + x + (i*x)**2 for i in range(cluster_num)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(major_sightseeing_venues['lat'], major_sightseeing_venues['lng'], major_sightseeing_venues['name'], major_sightseeing_venues['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(int(cluster)+1), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[int(cluster)-1],\n        fill=True,\n        fill_color=rainbow[int(cluster)-1],\n        fill_opacity=0.7).add_to(map_clusters2)\n       \nmap_clusters2",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<img src=\"https://imgur.com/BPB2F4p.png\">"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Looks like *Cluster 0 (Green dots)* has been excluded, since the attractions are too far away from the others.  "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "final_sightseeing_venues = major_sightseeing_venues[major_sightseeing_venues['Cluster Labels'] > -1] # Cluster number -1 is actually equivalent to Cluster 0, the tag name changes when creating folium map\nfinal_sightseeing_venues = final_sightseeing_venues.reset_index(drop = True)\nfinal_sightseeing_venues",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<img src=\"https://imgur.com/px8gqHu.png\">"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 4) Routing - Applying Google OR-Tools : Traveling Salesperson Problem"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Reference: https://developers.google.com/optimization/routing/tsp "
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Now we have the attraction clusters, let's determine the visiting order for these attractions! "
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "sightseeing_cluster = [final_sightseeing_venues_cluster1, final_sightseeing_venues_cluster2, final_sightseeing_venues_cluster3]\n\nfrom ortools.constraint_solver import routing_enums_pb2\nfrom ortools.constraint_solver import pywrapcp\n\n\nfor k in sightseeing_cluster:\n\n    def build_distance_matrix(dff):\n        \"\"\"Distance matrix: Calculate the distance between venue and venue\"\"\"\n        \n        dff['distance_matrix'] = ''\n        for i in range(0,len(dff)):\n            distance_matrix = []\n            for j in range(0,len(dff)):\n                distance_matrix.append(int(round((math.sqrt(pow(float(dff['lat'][i])-float(dff['lat'][j]),2) + pow(float(dff['lng'][i])-float(dff['lng'][j]),2))*111320))))\n            dff['distance_matrix'][i] = distance_matrix\n        return list(dff['distance_matrix'])\n\n    def create_data_model():\n        \"\"\"Stores the data for the problem.\"\"\"\n        data = {}\n        data['distance_matrix'] = build_distance_matrix(k)\n        data['num_vehicles'] = 1\n        data['depot'] = 0\n        data['name'] =list(k['name'])\n        return data\n\n    def print_solution(data, manager, routing, solution):\n        \"\"\"Prints solution on console.\"\"\"\n        print('Objective Trip Distance: {} miles'.format(solution.ObjectiveValue()))\n        index = routing.Start(0)\n        plan_output = 'Route Order for Trip Cluster:\\n'\n        route_distance = 0\n        \n        while not routing.IsEnd(index):\n            node_index = manager.IndexToNode(index)\n            plan_output += str(data['name'][manager.IndexToNode(index)]) + ' -> '\n            \n            previous_index = index\n            \n            index = solution.Value(routing.NextVar(index))\n            route_distance += routing.GetArcCostForVehicle(previous_index, index, 0)\n        \n        plan_output += ' {}\\n'.format(manager.IndexToNode(index))\n        \n        print(plan_output)\n        plan_output += 'Route distance: {}miles\\n'.format(route_distance)\n\n\n    def main():\n        \"\"\"Entry point of the program.\"\"\"\n        # Instantiate the data problem.\n        data = create_data_model()\n\n        # Create the routing index manager.\n        manager = pywrapcp.RoutingIndexManager(len(data['distance_matrix']),\n                                           data['num_vehicles'], data['depot'])\n\n        # Create Routing Model.\n        routing = pywrapcp.RoutingModel(manager)\n\n\n        def distance_callback(from_index, to_index):\n            \"\"\"Returns the distance between the two nodes.\"\"\"\n            # Convert from routing variable Index to distance matrix NodeIndex.\n            from_node = manager.IndexToNode(from_index)\n            to_node = manager.IndexToNode(to_index)\n            return data['distance_matrix'][from_node][to_node]\n\n        transit_callback_index = routing.RegisterTransitCallback(distance_callback)\n\n        # Define cost of each arc.\n        routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\n\n        # Setting first solution heuristic.\n        search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n        search_parameters.first_solution_strategy = (\n            routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC)\n\n        # Solve the problem.\n        solution = routing.SolveWithParameters(search_parameters)\n\n        # Print solution on console.\n        if solution:\n            print_solution(data, manager, routing, solution)\n\n\n    if __name__ == '__main__':\n        main()\n        ",
            "execution_count": null,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "<img src=\"https://imgur.com/jcjhnUH.png\">"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "### 5) Results and Conclusion"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "Finally, we come out with the trip detail and visit order for these 3 days, now we are able to make tour arrangements for our time-constrained customers. <br><br>\n\n**Day 1** <br>\n<li> Start from \"Lincoln Square\", and first we will visit \"Museum of Modern Art (MoMA)\"</li>\n<li> After that, we will visit \"St. Patrick's Cathedral\".</li>\n<li> Then, we will go to \"Top of the Rock Observation Deck\" and have lunch nearby.</li>\n<li> After lunch, we will go to \"Radio City Music Hall\". </li>\n<li> Then, we will go to \"Winter Garden Theatre\" and \"Majestic Theatre\".</li>\n<li> Then, we will enjoy a show at \"Gershwin Theatre\".</li>\n<li> Finally, let's have some food and drinks in the bars nearby.    </li>\n<br>\n\n**Day 2** <br>\n<li> First of all, we will go to \"Shakespeare Garden\" and \"Delacorte Theater\". </li>\n<li> After that, we will visit The \"Metropolitan Museum of Art (Metropolitan Museum of Art)\" and have lunch nearby. </li>\n<li> After lunch, we will visit \"Temple of Dendur\". </li>\n<li> Then, we will go to \"Jacqueline Kennedy Onassis Reservoir\" and \"Central Park\". </li>\n<li> Finally, let's shop nearby. </li>\n<br>\n\n**Day 3** <br>\n<li> First of all, we will visit \"Gagosian Gallery\". </li>\n<li> After that, we will go to \"Pier 63 Hudson River Park\" and have lunch nearby. </li>\n<li> After lunch, we will visit \"David Zwirner Gallery\". </li>\n<li> Then, we will go to \"High Line 10th Ave Amphitheatre\" and \"Chelsea Market\". </li>\n<li> Finally, let's go to \"High Line\" for our last stop in New York City. Enjoy the skyline of New York City! </li>\n<br>\n<br>\nThe purpose of this problem is to help foreign travellers (especially for those who have never been to New York City before (like ME)) to quickly arrange the visiting order of the top attractions in a scientific and reasonable way."
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "------------------------------------------------------------------------------------------------------------------------"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "The detailed code is available on <a href=\"https://github.com/PrestonYU/Coursera_Capstone/blob/master/Capstone_Project_wk4_and_5.ipynb\">Github</a>. (<a href=\"https://nbviewer.jupyter.org/github/PrestonYU/Coursera_Capstone/blob/master/Capstone_Project_wk4_and_5.ipynb\">nbviewer</a>) "
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.7",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.7.10",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}